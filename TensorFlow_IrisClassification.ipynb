{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow_IrisClassification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Ritesh0100/MLtries/blob/master/TensorFlow_IrisClassification.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "CfRrZCkdTy3s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Getting started with graph execution - Iris Classification Problem\n",
        "#https://www.tensorflow.org/get_started/get_started_for_beginners : using Estimator and DataSet_API\n",
        "\n",
        "TRAIN_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
        "TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h9h-vuSYb3hu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import argparse #not used here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WKLqqvM6cCdC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth',\n",
        "                    'PetalLength', 'PetalWidth', 'Species']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n246d8BrcF8J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Loading and parsing data; tf.keras is a TensorFlow implementation of Keras\n",
        "def load_data(label_name='Species'):\n",
        "   \n",
        "    # Create a local copy of the training set.\n",
        "    train_path = tf.keras.utils.get_file(fname=TRAIN_URL.split('/')[-1],\n",
        "                                         origin=TRAIN_URL)\n",
        "    # train_path now holds the pathname: ~/.keras/datasets/iris_training.csv\n",
        "\n",
        "    \n",
        "    # Parse the local CSV file to Data frame\n",
        "    train = pd.read_csv(filepath_or_buffer=train_path,\n",
        "                        names=CSV_COLUMN_NAMES,  # list of column names\n",
        "                        header=0  # ignore the first row of the CSV file.\n",
        "                       )\n",
        "    \n",
        "    #dividing Data to features and label\n",
        "    train_features, train_label = train, train.pop(label_name)\n",
        "\n",
        "    # Apply the preceding logic to the test set.\n",
        "    test_path = tf.keras.utils.get_file(TEST_URL.split('/')[-1], TEST_URL)\n",
        "    test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\n",
        "    test_features, test_label = test, test.pop(label_name)\n",
        "\n",
        "    # Return four DataFrames.\n",
        "    return (train_features, train_label), (test_features, test_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QVv8_2nfc9dV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Call load_data() to parse the CSV file.\n",
        "(train_feature, train_label), (test_feature, test_label) = load_data()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gH-aIvs6diQs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create feature columns for all features; telling type of data to expect\n",
        "train_x = train_feature\n",
        "my_feature_columns = []\n",
        "for key in train_x.keys():\n",
        "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P0fcgcXTemSO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "fb013950-8b44-44f7-8ff7-66bf1428664b"
      },
      "cell_type": "code",
      "source": [
        "#making Neural Net Model\n",
        "classifier = tf.estimator.DNNClassifier(\n",
        "        feature_columns=my_feature_columns,\n",
        "        hidden_units=[10, 10],\n",
        "        n_classes=3) #here we didn't specify optimizer "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpvuuok3e_\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpvuuok3e_', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb64dc9fda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "swWwKUeWfU9y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_input_fn(features, labels, batch_size):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
        "  dataset = dataset.shuffle(buffer_size=1000).repeat(count=None).batch(batch_size)\n",
        "  #Setting the buffer_size to a value larger than the number of examples (120) ensures that the data will be well shuffled\n",
        "  return dataset.make_one_shot_iterator().get_next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f4l5A8YfhyQA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "ccc8f088-44dc-4d6e-9a81-8a04089c0f7f"
      },
      "cell_type": "code",
      "source": [
        "classifier.train(\n",
        "        input_fn=lambda:train_input_fn(train_feature, train_label, 1000),steps=1000)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpvuuok3e_/model.ckpt.\n",
            "INFO:tensorflow:loss = 2542.9434, step = 1\n",
            "INFO:tensorflow:global_step/sec: 122.742\n",
            "INFO:tensorflow:loss = 169.52368, step = 101 (0.822 sec)\n",
            "INFO:tensorflow:global_step/sec: 219.923\n",
            "INFO:tensorflow:loss = 96.872284, step = 201 (0.453 sec)\n",
            "INFO:tensorflow:global_step/sec: 198.272\n",
            "INFO:tensorflow:loss = 75.48589, step = 301 (0.505 sec)\n",
            "INFO:tensorflow:global_step/sec: 219.606\n",
            "INFO:tensorflow:loss = 67.08708, step = 401 (0.453 sec)\n",
            "INFO:tensorflow:global_step/sec: 216.711\n",
            "INFO:tensorflow:loss = 60.53917, step = 501 (0.465 sec)\n",
            "INFO:tensorflow:global_step/sec: 224.785\n",
            "INFO:tensorflow:loss = 56.636253, step = 601 (0.438 sec)\n",
            "INFO:tensorflow:global_step/sec: 223.563\n",
            "INFO:tensorflow:loss = 51.525948, step = 701 (0.453 sec)\n",
            "INFO:tensorflow:global_step/sec: 216.67\n",
            "INFO:tensorflow:loss = 48.14349, step = 801 (0.460 sec)\n",
            "INFO:tensorflow:global_step/sec: 224.072\n",
            "INFO:tensorflow:loss = 46.681183, step = 901 (0.446 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmpvuuok3e_/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 44.91907.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x7fb64dc9ff98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "ErpMUmPShZtz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Evaluating model performance\n",
        "def eval_input_fn(features, labels=None, batch_size=None):\n",
        "    \"\"\"An input function for evaluation or prediction\"\"\"\n",
        "    features = dict(features)\n",
        "    if labels is None:\n",
        "        # No labels, use only features.\n",
        "        inputs = features\n",
        "    else:\n",
        "        inputs = (features, labels)\n",
        "\n",
        "    # Convert inputs to a tf.dataset object.\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
        "\n",
        "    # Batch the examples\n",
        "    assert batch_size is not None, \"batch_size must not be None\"\n",
        "    dataset = dataset.batch(batch_size)\n",
        "\n",
        "    # Return the read end of the pipeline.\n",
        "    return dataset.make_one_shot_iterator().get_next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "beB_KyO7lRSd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "8930ab13-2367-48b5-c08c-c9ed90f3ed1c"
      },
      "cell_type": "code",
      "source": [
        "# Evaluate the model.\n",
        "\n",
        "eval_result = classifier.evaluate(\n",
        "    input_fn=lambda:eval_input_fn(test_feature, test_label, 1000))\n",
        "\n",
        "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-06-30-12:58:28\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpvuuok3e_/model.ckpt-1000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2018-06-30-12:58:28\n",
            "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.93333334, average_loss = 0.070706174, global_step = 1000, loss = 2.1211853\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: /tmp/tmpvuuok3e_/model.ckpt-1000\n",
            "\n",
            "Test set accuracy: 0.933\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a4U1FaKKn1ca",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#using model\n",
        "predict_x = {\n",
        "        'SepalLength': [5.1, 5.9, 6.9],\n",
        "        'SepalWidth': [3.3, 3.0, 3.1],\n",
        "        'PetalLength': [1.7, 4.2, 5.4],\n",
        "        'PetalWidth': [0.5, 1.5, 2.1],\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mtv91EZclYUy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions = classifier.predict(\n",
        "    input_fn=lambda:eval_input_fn(predict_x,\n",
        "                                  labels=None,\n",
        "                                  batch_size=1000))\n",
        "\n",
        "expected = ['Setosa', 'Versicolor', 'Virginica']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hOuW5xw6xwyH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "be4fd2e6-ea39-4815-c4c7-4b466e60c020"
      },
      "cell_type": "code",
      "source": [
        "for pred_dict, expec in zip(predictions, expected):\n",
        "    template = ('\\nPrediction is \"{}\" ({:.1f}%), expected \"{}\"')\n",
        "\n",
        "    class_id = pred_dict['class_ids'][0]\n",
        "    probability = pred_dict['probabilities'][class_id]\n",
        "    print(template.format(expected[class_id], 100 * probability, expec))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Prediction is \"Versicolor\" (99.8%), expected \"Setosa\"\n",
            "\n",
            "Prediction is \"Virginica\" (99.0%), expected \"Versicolor\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EwiLxAsGyYWl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}